2.

# Imports required packages

import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist
from sklearn.model_selection import train_test_split

# Loads fashion mnist dataset
fashion = fashion_mnist.load_data()

# Considering dataset is organized in tuple, items are referenced as follows
(X_train_full, y_train_full), (X_test, y_test) = fashion

# Checks the shape of the datasets
print("Train dataset shape:", X_train_full.shape,
      "\nTest dataset shape:", X_test.shape)

# Each training and test example is assigned to one of the following labels.
class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat", "Sandal", \
               "Shirt", "Sneaker", "Bag", "Ankle boot"]

# Normalizes the data between 0 and 1 for effective neural network model training
X_train_full, X_test = X_train_full / 255., X_test / 255.

# Splits train dataset further to seperate 5000 instances to be used as validation set

X_train, X_val, y_train, y_val = train_test_split(
    X_train_full, y_train_full, test_size=5000, random_state=42, stratify=y_train_full)

# Stores class ids of the target items into variables.
# In this case, variable pos_class_id and neg_class_id will store 2 and 0, respectively.
# Also, item "Pullover" and "T-shirt/top" are considered as positive and negative class, respectively.

pos_class_id = class_names.index("Pullover")
neg_class_id = class_names.index("T-shirt/top")

def split_dataset(X, y):
    """
    Splits the dataset having all items into a pair of tuples - one for dataset for 8-class classification task
    and other one for dataset for the remaining 2-class classification task.
    """
    y_for_B = (y == pos_class_id) | (y == neg_class_id)
    y_A = y[~y_for_B]
    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)
    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))
    for old_class_id, new_class_id in zip(old_class_ids, range(8)):
        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A
        
    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))

# Splits train, validation and test data into respective dataset for classification task A and B

(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)
(X_val_A, y_val_A), (X_val_B, y_val_B) = split_dataset(X_val, y_val)
(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)

# Considers only 200 instances for training for classification task B
X_train_B = X_train_B[:200]
y_train_B = y_train_B[:200]

# Creates a dense nueral network for classification task A

tf.random.set_seed(42)

model_A = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=[28, 28]),
    tf.keras.layers.Dense(100, activation="relu", kernel_initializer="he_normal"),
    tf.keras.layers.Dense(100, activation="relu", kernel_initializer="he_normal"),
    tf.keras.layers.Dense(100, activation="relu", kernel_initializer="he_normal"),
    tf.keras.layers.Dense(8, activation="softmax")
])

model_A.compile(loss="sparse_categorical_crossentropy",
                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
                metrics=["accuracy"])

# Fits the model.
history = model_A.fit(X_train_A, y_train_A, epochs=20, validation_data=(X_val_A, y_val_A))

# Saves the model to be used later for transfer learning
# NOTE: Make sure the folder "models" exists under the current working directory

model_A.save("./models/my_fashion_mnist_model_A.keras")

# Creates a dense nueral network for classification task B

tf.random.set_seed(42)

model_B = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=[28, 28]),
    tf.keras.layers.Dense(100, activation="relu", kernel_initializer="he_normal"),
    tf.keras.layers.Dense(100, activation="relu", kernel_initializer="he_normal"),
    tf.keras.layers.Dense(100, activation="relu", kernel_initializer="he_normal"),
    tf.keras.layers.Dense(1, activation="sigmoid")
])

model_B.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
                metrics=["accuracy"])

# Fits the model.
history = model_B.fit(X_train_B, y_train_B, epochs=20, validation_data=(X_val_B, y_val_B))

# Evaluates the model on test dataset
model_B.evaluate(X_test_B, y_test_B)

# Loads the model trained for classification task A
model_A = tf.keras.models.load_model("./models/my_fashion_mnist_model_A.keras")

# Creates a new model copies all the layers, except for the output layer, from model A
# to be reused for classification task B
model_B_on_A = tf.keras.Sequential(model_A.layers[:-1])

# Just one-node output layer is added into the new model
model_B_on_A.add(tf.keras.layers.Dense(1, activation="sigmoid"))

tf.random.set_seed(42)

# Network architecture of model A is cloned into a new model
model_A_clone = tf.keras.models.clone_model(model_A)

# Learned weigts of the model A are copied into the new cloned model
model_A_clone.set_weights(model_A.get_weights())

# Creates model_B_on_A just like in the previous cell

# Like the previous steps, creates target model B cloning all layers, except for the output layer,
# and then adds a one-node output layer onto it

model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])
model_B_on_A.add(tf.keras.layers.Dense(1, activation="sigmoid"))

# Freezes all the hidden layers before training
for layer in model_B_on_A.layers[:-1]:
    layer.trainable = False

optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)
model_B_on_A.compile(loss="binary_crossentropy", optimizer=optimizer, metrics=["accuracy"])

# Fits the model over a shorter iteration to train only the output layer
history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_val_B, y_val_B))

# Then allows hidden layers trainable before next iterations of training
for layer in model_B_on_A.layers[:-1]:
    layer.trainable = True

optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)
model_B_on_A.compile(loss="binary_crossentropy", optimizer=optimizer, metrics=["accuracy"])

# Fits the full model.
history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16, validation_data=(X_val_B, y_val_B))

# Once again, evaluates the model B against test dataset
model_B_on_A.evaluate(X_test_B, y_test_B)

